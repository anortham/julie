[tokenizer]
# Character sequences to preserve as single tokens
preserve_patterns = [
    "=>",   # lambda / expression body
    "?.",   # null conditional
    "??",   # null coalescing
    "??=",  # null coalescing assignment
    "::",   # global/alias qualifier
    "&&",   # logical and
    "||",   # logical or
    "<>",   # generics
]

# Naming conventions to recognize
naming_styles = ["PascalCase", "camelCase", "SCREAMING_SNAKE_CASE"]

# Prefixes/suffixes with semantic meaning
meaningful_affixes = [
    "Is",
    "Has",
    "Can",
    "Get",
    "Set",
    "On",
    "I",
    "_",
    "Async",
]

[variants]
strip_prefixes = ["I", "_"]
strip_suffixes = ["Async", "Handler", "Service", "Controller", "Repository"]

[scoring]
important_patterns = [
    "public class",
    "public interface",
    "public enum",
    "public struct",
    "async Task",
    "[ApiController]",
]
