/// Parallel extraction engine for high-performance bulk operations
///
/// Uses Rayon for parallel file processing and supports direct SQLite writes
/// for maximum performance. Designed to handle large workspaces efficiently.

use crate::database::SymbolDatabase;
use crate::extractors::base::Symbol;
use crate::extractors::ExtractorManager;
use anyhow::{anyhow, Result};
use rayon::prelude::*;
use std::path::PathBuf;
use std::sync::{Arc, Mutex};
use walkdir::WalkDir;

/// Configuration for parallel extraction
#[derive(Debug, Clone)]
pub struct ExtractionConfig {
    /// Number of parallel threads (defaults to CPU count)
    pub num_threads: usize,

    /// Batch size for processing (symbols processed before DB write)
    pub batch_size: usize,

    /// Optional SQLite database path for direct writes (fastest for bulk)
    pub output_db: Option<String>,
}

impl Default for ExtractionConfig {
    fn default() -> Self {
        Self {
            num_threads: num_cpus::get(),
            batch_size: 100,
            output_db: None,
        }
    }
}

/// High-performance parallel extractor
pub struct ParallelExtractor {
    config: ExtractionConfig,
}

impl ParallelExtractor {
    /// Create a new parallel extractor with the given configuration
    pub fn new(config: ExtractionConfig) -> Self {
        Self { config }
    }

    /// Extract all files in a directory (parallel, optimized for bulk operations)
    ///
    /// Performance: ~200 files/sec on 8 cores with SQLite output
    pub fn extract_directory(&self, directory: &str) -> Result<Vec<Symbol>> {
        // 1. Setup thread pool
        rayon::ThreadPoolBuilder::new()
            .num_threads(self.config.num_threads)
            .build_global()
            .map_err(|e| anyhow!("Failed to build thread pool: {}", e))?;

        // 2. Discover all supported files
        let files = self.discover_files(directory)?;
        eprintln!("üìÅ Found {} files to process", files.len());

        if files.is_empty() {
            return Ok(Vec::new());
        }

        // 3. Setup output (SQLite or in-memory)
        let db = if let Some(db_path) = &self.config.output_db {
            let db = Arc::new(Mutex::new(SymbolDatabase::new(db_path)?));
            eprintln!("üóÑÔ∏è  SQLite database opened: {}", db_path);
            Some(db)
        } else {
            None
        };

        // 4. Process files in parallel batches
        let all_symbols = Arc::new(Mutex::new(Vec::new()));
        let processed = Arc::new(Mutex::new(0usize));
        let total_files = files.len();

        files
            .par_chunks(self.config.batch_size)
            .for_each(|batch| {
                // Extract symbols for this batch (parallel within batch)
                let batch_symbols: Vec<Symbol> = batch
                    .par_iter()
                    .flat_map(|file| {
                        // TODO: Make extraction synchronous or use tokio runtime properly
                        self.extract_file_sync(file).ok().unwrap_or_default()
                    })
                    .collect();

                // Write to output
                if let Some(ref db) = db {
                    // Direct SQLite write (using default workspace for CLI)
                    if let Ok(mut db_lock) = db.lock() {
                        if let Err(e) = db_lock.bulk_store_symbols(&batch_symbols, "cli-extraction") {
                            eprintln!("‚ö†Ô∏è  Failed to store batch: {}", e);
                        }
                    }
                } else {
                    // Collect in memory
                    if let Ok(mut symbols) = all_symbols.lock() {
                        symbols.extend(batch_symbols);
                    }
                }

                // Progress reporting
                if let Ok(mut proc) = processed.lock() {
                    *proc += batch.len();
                    if *proc % 100 == 0 || *proc == total_files {
                        eprintln!("‚ö° Processed {}/{} files", *proc, total_files);
                    }
                }
            });

        // 5. Finalize
        if let Some(db) = db {
            let db_lock = db
                .lock()
                .map_err(|e| anyhow!("Lock error during finalization: {}", e))?;

            eprintln!("‚úÖ Bulk insert complete");

            // Return symbols from DB
            return Ok(db_lock.get_all_symbols()?);
        }

        // Return collected symbols
        Ok(Arc::try_unwrap(all_symbols)
            .map_err(|_| anyhow!("Failed to unwrap symbols Arc"))?
            .into_inner()
            .map_err(|e| anyhow!("Lock error: {:?}", e))?)
    }

    /// Extract single file (for incremental updates)
    pub fn extract_file(&self, file_path: &str) -> Result<Vec<Symbol>> {
        let content = std::fs::read_to_string(file_path)?;
        let extractor_manager = ExtractorManager::new();
        extractor_manager.extract_symbols(file_path, &content)
    }

    /// Synchronous file extraction (for Rayon compatibility)
    fn extract_file_sync(&self, file_path: &PathBuf) -> Result<Vec<Symbol>> {
        let file_path_str = file_path.to_string_lossy().to_string();
        let content = std::fs::read_to_string(&file_path_str)?;

        let extractor_manager = ExtractorManager::new();

        // Now that extract_symbols is synchronous, we can call it directly
        extractor_manager.extract_symbols(&file_path_str, &content)
    }

    /// Discover all supported files in a directory
    fn discover_files(&self, directory: &str) -> Result<Vec<PathBuf>> {
        let mut files = Vec::new();

        for entry in WalkDir::new(directory)
            .into_iter()
            .filter_map(|e| e.ok())
        {
            if !entry.file_type().is_file() {
                continue;
            }

            if let Some(ext) = entry.path().extension() {
                if self.is_supported_extension(ext.to_str().unwrap_or("")) {
                    files.push(entry.path().to_path_buf());
                }
            }
        }

        Ok(files)
    }

    /// Check if file extension is supported
    fn is_supported_extension(&self, ext: &str) -> bool {
        matches!(
            ext,
            "rs" | "ts"
                | "tsx"
                | "js"
                | "jsx"
                | "py"
                | "java"
                | "cs"
                | "go"
                | "cpp"
                | "c"
                | "h"
                | "hpp"
                | "rb"
                | "php"
                | "swift"
                | "kt"
                | "dart"
                | "gd"
                | "lua"
                | "vue"
                | "razor"
                | "sql"
                | "html"
                | "css"
                | "sh"
                | "bash"
                | "ps1"
                | "zig"
        )
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use tempfile::tempdir;

    #[test]
    fn test_discover_files() {
        let dir = tempdir().unwrap();
        let test_file = dir.path().join("test.rs");
        std::fs::write(&test_file, "fn main() {}").unwrap();

        let config = ExtractionConfig::default();
        let extractor = ParallelExtractor::new(config);

        let files = extractor.discover_files(dir.path().to_str().unwrap()).unwrap();
        assert_eq!(files.len(), 1);
    }

    #[test]
    fn test_extract_file() {
        let dir = tempdir().unwrap();
        let test_file = dir.path().join("test.rs");
        std::fs::write(&test_file, "fn main() {}").unwrap();

        let config = ExtractionConfig::default();
        let extractor = ParallelExtractor::new(config);

        let symbols = extractor
            .extract_file(test_file.to_str().unwrap())
            .unwrap();

        assert!(!symbols.is_empty());
    }

    /// This test verifies the fix for the "Cannot start a runtime from within a runtime" bug.
    ///
    /// The bug was:
    /// 1. extract_directory was async (running in tokio runtime)
    /// 2. Rayon parallel iterator called extract_file_sync
    /// 3. extract_file_sync tried to create a NEW runtime with Runtime::new()
    /// 4. PANIC: nested runtime creation
    ///
    /// The fix:
    /// - Made extract_symbols synchronous (it doesn't need to be async)
    /// - Removed Runtime::new() from extract_file_sync
    /// - Now works perfectly without any runtime nesting
    #[test]
    fn test_bulk_extraction_no_runtime_panic() {
        let dir = tempdir().unwrap();
        let test_file = dir.path().join("test.rs");
        std::fs::write(&test_file, "fn main() { println!(\"test\"); }").unwrap();

        // This config triggers the bulk code path with SQLite
        let db_path = dir.path().join("test.db");
        let config = ExtractionConfig {
            num_threads: 2,
            batch_size: 1,
            output_db: Some(db_path.to_string_lossy().to_string()),
        };

        let extractor = ParallelExtractor::new(config);

        // This should now work without panicking!
        let symbols = extractor
            .extract_directory(dir.path().to_str().unwrap())
            .unwrap();

        // Verify we actually extracted symbols
        assert!(!symbols.is_empty(), "Should have extracted at least one symbol");
    }
}
